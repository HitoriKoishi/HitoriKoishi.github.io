<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>LLM-CS336 | Aris系统已上线</title><meta name="author" content="HitoriKoishi"><meta name="copyright" content="HitoriKoishi"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="从头构建大模型说是🔥☢️  标记化 字节对编码标记器（BPE） 在字符分割中，可以直接使用Unicode转为UTF-8的方式产生字节编码序列 使用 re.escape 防止特殊字符被误解释（通过加入转义的方式避免正则判断出现错误），并使用 re.split 将特殊字符作为分割点分离原始文本 12345678910111213141516import regex as re# 多个特殊标记spe">
<meta property="og:type" content="article">
<meta property="og:title" content="LLM-CS336">
<meta property="og:url" content="https://hitorikoishi.github.io/2025/10/20/LLM-CS336/index.html">
<meta property="og:site_name" content="Aris系统已上线">
<meta property="og:description" content="从头构建大模型说是🔥☢️  标记化 字节对编码标记器（BPE） 在字符分割中，可以直接使用Unicode转为UTF-8的方式产生字节编码序列 使用 re.escape 防止特殊字符被误解释（通过加入转义的方式避免正则判断出现错误），并使用 re.split 将特殊字符作为分割点分离原始文本 12345678910111213141516import regex as re# 多个特殊标记spe">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://hitorikoishi.github.io/img/background_2.jpg">
<meta property="article:published_time" content="2025-10-20T08:18:25.000Z">
<meta property="article:modified_time" content="2025-11-10T06:52:26.525Z">
<meta property="article:author" content="HitoriKoishi">
<meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://hitorikoishi.github.io/img/background_2.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "LLM-CS336",
  "url": "https://hitorikoishi.github.io/2025/10/20/LLM-CS336/",
  "image": "https://hitorikoishi.github.io/img/background_2.jpg",
  "datePublished": "2025-10-20T08:18:25.000Z",
  "dateModified": "2025-11-10T06:52:26.525Z",
  "author": [
    {
      "@type": "Person",
      "name": "HitoriKoishi",
      "url": "https://hitorikoishi.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://hitorikoishi.github.io/2025/10/20/LLM-CS336/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'LLM-CS336',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="Aris系统已上线" type="application/atom+xml">
<link rel="alternate" href="/rss.xml" title="Aris系统已上线" type="application/rss+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">5</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">5</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/background_2.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Aris系统已上线</span></a><a class="nav-page-title" href="/"><span class="site-name">LLM-CS336</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">LLM-CS336</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-10-20T08:18:25.000Z" title="发表于 2025-10-20 16:18:25">2025-10-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-11-10T06:52:26.525Z" title="更新于 2025-11-10 14:52:26">2025-11-10</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><blockquote>
<p>从头构建大模型说是🔥☢️</p>
</blockquote>
<h1 id="biao-ji-hua" id="标记化">标记化</h1>
<h2 id="zi-jie-dui-bian-ma-biao-ji-qi-bpe" id="字节对编码标记器（BPE）">字节对编码标记器（BPE）</h2>
<p>在字符分割中，可以直接使用Unicode转为UTF-8的方式产生字节编码序列</p>
<p>使用 re.escape 防止特殊字符被误解释（通过加入转义的方式避免正则判断出现错误），并使用 re.split 将特殊字符作为分割点分离原始文本</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> regex <span class="keyword">as</span> re</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多个特殊标记</span></span><br><span class="line">special_tokens = [<span class="string">&quot;&lt;|endoftext|&gt;&quot;</span>, <span class="string">&quot;&lt;|startoftext|&gt;&quot;</span>, <span class="string">&quot;&lt;|pad|&gt;&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建分割模式</span></span><br><span class="line"><span class="comment"># 使用 re.escape 防止特殊字符被误解释</span></span><br><span class="line">delimiter_pattern = <span class="string">&quot;|&quot;</span>.join(re.escape(token) <span class="keyword">for</span> token <span class="keyword">in</span> special_tokens)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Pattern:&quot;</span>, delimiter_pattern)</span><br><span class="line"><span class="comment"># 输出: &lt;\|endoftext\|&gt;|&lt;\|startoftext\|&gt;|&lt;\|pad\|&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 re.split 分割文本</span></span><br><span class="line">text = <span class="string">&quot;Hello world&lt;|endoftext|&gt;This is another document&lt;|startoftext|&gt;And another&lt;|pad|&gt;Final text&quot;</span></span><br><span class="line">documents = re.split(delimiter_pattern, text)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Split result:&quot;</span>, documents)</span><br><span class="line"><span class="comment"># 输出: [&#x27;Hello world&#x27;, &#x27;This is another document&#x27;, &#x27;And another&#x27;, &#x27;Final text&#x27;]</span></span><br></pre></td></tr></table></figure>
<p>一些加速方法，例如 <strong>BPE 算法</strong>迭代地统计每对字节，并识别出出现频率最高的字节对，将字节对表示为一个新的词库（在 0 ~ 255 外的一个数字，样例中定义为 256 ）。该方法能够通过迭代一定的次数减少token的长度</p>
<blockquote>
<p>这样做，token中所包含的信息会不会进一步让机器难以总结？🤔🤔</p>
</blockquote>
<p>与此同时，可以将大的数据文件切分成4KB左右大小的区块（保证一篇完整的文章不会从中间被切分）以便并行训练模型</p>
<h1 id="pytorch" id="pytorch">pytorch</h1>
<h2 id="zhang-liang" id="张量">张量</h2>
<p>张量的连续与否取决于该张量在内存中的储存是否连续，当你遇到 <code>view()</code> 报错（ <code>view()</code> 要求张量在内存中是连续的，因为它只是重新解释一个连续内存块的含义）或追求极致性能时，就需要考虑并使用 <code>.contiguous()</code> 来修复它。</p>
<p>对于提取张量中的列，行，提取试图，转置等均不会创建原始张量的副本，**但<code>.contiguous()</code> 和 <code>.reshape()</code> 操作会返回一个在内存中连续存储的、包含相同数据的张量副本。**在使用时要谨慎</p>
<h1 id="jia-gou-yu-chao-can-shu" id="架构与超参数">架构与超参数</h1>
<h2 id="he-xin-jia-gou" id="核心架构">核心架构</h2>
<h3 id="biao-zhun-hua" id="标准化">标准化</h3>
<p>layernorm 等正则化虽然只使用了极少的 FLOP ，但仍会耗费较多运行时间在内存移动上</p>
<p><strong>相比于 layernorm ，RMS norm 不会减去均值并去除 β 参数，使得内存效率提高</strong></p>
<p>去除偏差项会提高模型训练的稳定度，目前大多数大模型完全省略偏差项，仅在矩阵乘法类型上进行运算</p>
<p><strong>目前基本上正确的做法是 pre-norm ，并且在残差流之外进行 LayerNorms，可以获得更好的梯度传播，更稳定的训练</strong></p>
<h3 id="ji-huo-han-shu" id="激活函数">激活函数</h3>
<p>目前最新的模型都使用门控线性单元 SwiGLU 、 GeGLU</p>
<p>GLU 有一个额外的超参数 V ，对于门控单元，要将待乘矩阵缩小一些以确保一切保持参数匹配</p>
<h3 id="jia-gou" id="架构">架构</h3>
<p>串行 or 并行</p>
<p>目前大多数模型依旧采用串行架构</p>
<h3 id="wei-zhi-qian-ru" id="位置嵌入">位置嵌入</h3>
<p>目前大多数模型采用 Rope embeddings</p>
<p>Rope embeddings 旋转矢量，旋转角度由每个单词的位置和旋转决定</p>
<p>其中确定角度的 θ 有一个时间表（类似于 sin cos 位置嵌入），可覆盖不同的频率范围以获取更高或更低频率的信息</p>
<p>相对定位信息至关重要</p>
<blockquote>
<p><strong>Rope 作用原理仍需补充♿♿♿</strong></p>
</blockquote>
<h2 id="chao-can-shu" id="超参数">超参数</h2>
<h3 id="qian-kui-ceng-wei-du" id="前馈层维度">前馈层维度</h3>
<p>从经验角度上讲，前馈层的维度等于 4 倍模型维度是较优的</p>
<p>若使用 GLU ，前馈层的维度等于 8/3 倍模型维度</p>
<p>前馈层矩阵越宽，能得到更多的并行计算，更好的系统优化收益，与扩大隐藏单元的作用方式不同</p>
<h3 id="tou-bu-wei-du-yu-tou-bu-shu-liang" id="头部维度与头部数量">头部维度与头部数量</h3>
<p>头部维度 == 模型维度 / 头部数量</p>
<p>这只是一般共识，可以作出一些改变</p>
<h3 id="zong-heng-bi" id="纵横比">纵横比</h3>
<p>模型维度 / 网络层数</p>
<p>通常最佳点为 128 ，早期模型的该比例一般较小</p>
<p>较好的区间为 100 - 200</p>
<h3 id="ci-ku-da-xiao-vocabulary-size" id="词库大小（vocabulary-size）">词库大小（vocabulary size）</h3>
<p>呈一个上升趋势</p>
<p>已出世的生产化模型在 100 - 250k token 数量范围</p>
<h2 id="jian-zhi-ji-yi-xie-qi-ta-zheng-ze-hua" id="剪枝及一些其他正则化">剪枝及一些其他正则化</h2>
<p>剪枝（drop out）逐渐不再受青睐（大模型目前不存在过拟合的问题，甚至无法对训练数据进行一次迭代），权重衰减（weight decay）成为新兴</p>
<p>不是为了控制过拟合（权重衰减大小与训练集和验证集的损失比例无关）， 而是与优化器的学习率发生作用，存在一些非常复杂的交互，因此其适用于更好的训练效果而不是避免过拟合</p>
<h2 id="wen-ding-xing-ji-qiao" id="稳定性技巧">稳定性技巧</h2>
<p>在训练时范数梯度和损失会遇到很多异常的由梯度爆炸造成的峰值</p>
<p>一般在 softmax 函数上出现该问题</p>
<p>可以使用 z-loss 替代 output softmax 来缓解这一问题</p>
<p>使用 QK norm 替代注意力机制中的 softmax 产生稳定输出，是种非常严厉的干预</p>
<p>也可以无脑加 layer norm （乐🤣）</p>
<p><strong>在推理时仍然使用 layer norm ，layer norm 已经学习到了参数，去除会大幅改变模型参数</strong></p>
<p>Logit soft-capping 没见过的新技术，通过tanh转换一些最大值</p>
<h2 id="zhu-yi-li-tou" id="注意力头">注意力头</h2>
<p>GQA / MQA</p>
<p>算术强度：总计算操作开销 / 总内存访问开销，越大越好。GPU内存访问开销相对较大，目的是在单次内存访问中做尽可能多的计算（大数量的头，大的批量大小，大的序列长度都能提高这一指标）</p>
<p>在推理时需要 KV cache 技术来增量式更新注意力来进行高校推理，避免整个 QK 矩阵的计算，处理绝对必要的 Key 和 Value 矩阵部分，<strong>但这会带来更高的内存访问量🤔</strong></p>
<p>MQA 设置多个查询头，但对于键和值只能设置一个维度或一个头</p>
<p>GQA 增加键和值的头</p>
<p>稀疏注意力机制仅关注部分矩阵，权衡各种表达能力和运行时间，以此获得更大的注意力窗口</p>
<p>滑动窗口注意力机制，在每一层只关注当前位置周围的一小块区域，控制所需的资源总量</p>
<p>Transfomer Block，可以定义一些层使用完全自注意力或者滑动窗口自注意力（使用RoPE）</p>
<h1 id="zhuan-jia-hun-he-xi-tong-mo-e" id="专家混合系统（MoE）">专家混合系统（MoE）</h1>
<p>MoE对比密集架构模型就是好用😋</p>
<h2 id="jia-gou-1" id="架构-2">架构</h2>
<p>用选择器层和许多较小的层来替换左侧的大的前馈层，在每次前向传递或每次推理中选择较少数量的副本</p>
<p><strong>专家网络</strong>：一组不同的“子模型”（即专家）。每个专家通常是一个前馈神经网络，它们各自擅长处理特定类型或特定模式的数据。</p>
<p><strong>门控网络</strong>：一个“路由器”。它的作用是针对每一个输入（比如一个词或一个token），计算应该将输入分配给哪个（或哪些）专家，并决定最终组合这些专家输出时的权重。</p>
<p><strong>专家并行性</strong>：可以把每个专家分片到不同的设备上，只需要获取 token 并路由到适当的设备</p>
<p>基础设施很复杂，只有在多节点时才能发挥最大优势，并且路由选择的训练和所涉及的优化问题，其目标要么是启发式的，要么是不稳定的，所以没有将其推广到大模型之外</p>
<p>传统方法是把 MLP 层替换为 MoE 层，如今可以推广到注意力机制作为注意力头，但很少见</p>
<h2 id="she-ji" id="设计">设计</h2>
<p>有三种路由选择方法</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>token 选择专家 （Top-K 个专家）</p>
</li>
<li class="lvl-2">
<p>专家选择 token （每个专家选择 Top-K 个 token）</p>
</li>
<li class="lvl-2">
<p>全局专家与 token 的映射任务，可以尽可能平衡映射 （需要解决一些复杂的优化问题）</p>
</li>
</ul>
<p>几乎所有 MoE 都选择了 token choice topK 路由</p>
<p>K 这个超参数等于 2 是一个规范选择</p>
<blockquote>
<p>Top-K 路由公式，没错！是有一个公式在里面的</p>
</blockquote>
<blockquote>
<p>共享专家和细粒度专家</p>
</blockquote>
<h2 id="xun-lian" id="训练">训练</h2>
<h3 id="rl" id="RL">RL</h3>
<p>强化学习是“正确的解决方案”，但梯度变化和复杂性意味着它尚未得到广泛应用</p>
<h3 id="sui-ji-jin-si" id="随机近似">随机近似</h3>
<p>随即探索策略，通过随机添加扰动并对齐退火或执行各种操作，可控制MoE将进行的探索-利用平衡。专家会得到有时意想不到的 token ，这会使专家的专业性降低，但可能更加强大</p>
<p>或者对路由器对数进行乘性扰动，获得不那么脆弱的专家，但效果不如一些基于启发式损失方法</p>
<h3 id="qi-fa-shi-ping-heng-sun-shi" id="启发式平衡损失">启发式平衡损失</h3>
<blockquote>
<p>专家与 token 映射的平衡公式</p>
<p>以及 deepseek 提出的每个批次专家的 token 平衡和每个批次设备的 token 平衡</p>
</blockquote>
<p>DeepSeek v3 变种，给每个专家加入一个设置学习率的偏差进行平衡（辅助无损平衡）</p>
<p>如果不进行专家平衡损失，实际上多专家会退化为 2 专家，事实上该 MoE 可以做的更好</p>
<h3 id="sui-ji-xing" id="随机性">随机性</h3>
<p>MoE 有一个有趣的随机性来源——</p>
<p>令牌丢弃（token dropping） ：某个专家没有足够的内存容纳被分配的 token ，多余的 token 会被直接丢弃</p>
<h3 id="wen-ding-xing" id="稳定性">稳定性</h3>
<p>MoE 很难进行微调，使用 Float32 计算专家路由 （有时使用 z-loss ）替换softmax</p>
<blockquote>
<p>此处应有 z-loss 的公式</p>
</blockquote>
<h3 id="wei-diao" id="微调">微调</h3>
<p>使用稀疏模型会出现很多过拟合的情况</p>
<p>使用大量SFT数据或者将一些层替换为密集层，并只在密集层上微调</p>
<h3 id="sheng-ji-zai-zao-upcycling" id="升级再造（upcycling）">升级再造（upcycling）</h3>
<p>从原始密集模型中提取 MLP 层，复制多个副本后加入一些扰乱，新增一个从头初始化的路由器，然后就可以当成一个 MoE 开始训练</p>
<p>MoE十分擅长推理，并非每个 MLP 在推理时都处于活动状态</p>
<h2 id="deep-seek-v-3-fei-mo-e" id="DeepSeek-V3-非MoE">DeepSeek V3 - 非MoE</h2>
<p>MLA：多头潜在注意力</p>
<p>将头部投射到较低维的空间中，但与 RoPE 不兼容</p>
<p>MTP：对损失函数进行些许改变，可并行预测多个标记</p>
<h2 id="zong-jie" id="总结">总结</h2>
<p>MoE 充分利用了稀疏性——并非所有输入都需要完整的模型。离散路由很难，但 Top-k 启发式算法似乎有效。目前有大量经验证据表明，MoE 有效且经济高效。</p>
<h1 id="suo-fang-ding-lu" id="缩放定律">缩放定律</h1>
<p>使用小模型将其放大来改进工程技术</p>
<p>随着数据量或者模型大小的改变，我们期待模型表现出某些行为</p>
<p>参数量与误差的关系，数据和模型大小应该如何与性能相关</p>
<p>关键 Bacth size</p>
<h1 id="tui-li" id="推理">推理</h1>
<p>给定训练过的固定模型，根据提示生成响应</p>
<p>一些评价指标：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>首次令牌生成时间 (TTFT)：用户在令牌生成前等待的时间（对于交互式应用很重要）</p>
</li>
<li class="lvl-2">
<p>延迟（秒/令牌）：用户获取令牌的速度（对于交互式应用很重要）</p>
</li>
<li class="lvl-2">
<p>吞吐量（令牌/秒）：对于批处理应用很有用</p>
</li>
</ul>
<p>训练是可以并行的，基于transformer架构的推理还是只能自回归串行工作</p>
<p>KV cache 使用空间换时间，减少推理的令牌生成时间复杂度</p>
<p>延迟与吞吐量之间的权衡：</p>
<p>较小的批次大小可带来更好的延迟，但吞吐量较差</p>
<p>较大的批次大小可带来更好的吞吐量，但延迟较差</p>
<h2 id="tui-li-you-hua-jian-xiao-kv-cache" id="推理优化——减小-KV-cache">推理优化——减小 KV cache</h2>
<h3 id="gqa-group-query-attention" id="GQA（Group-query-attention）">GQA（Group-query-attention）</h3>
<p>键和值的数量会减少，查询会增多，跨头部共享</p>
<p>在减少内存使用的同时提高吞吐量</p>
<h3 id="mla-multi-head-latent-attention" id="MLA（Multi-head-latent-attention）">MLA（Multi-head latent attention）</h3>
<p>不改变键和值的数量，但会将其投影至低维空间</p>
<p>并且 MLA 在准确性上比 GQA 的表现更好</p>
<h3 id="cla-cross-layer-attention" id="CLA（Cross-layer-attention）">CLA（Cross-layer attention）</h3>
<p>跨层注意力，在各个层之间使用相同的键值投影</p>
<h3 id="ju-bu-zhu-yi-li" id="局部注意力">局部注意力</h3>
<p>只关注最相关的局部区域</p>
<p>有效上下文的规模与层数呈线性关系</p>
<p>KV Cache 大小可以独立于序列长度并保持一定大小，不会因为序列长度增加而增加</p>
<p>但表达能力不强，会损失一定准确度，因此将局部注意力和全局注意力层混合搭建</p>
<h2 id="tui-li-mo-xing-jia-gou-ti-huan" id="推理模型架构替换">推理模型架构替换</h2>
<p>Transformer 在设计时并没有考虑到繁重的推理工作负载</p>
<h3 id="zhuang-tai-kong-jian-mo-xing-state-space-model" id="状态空间模型（State-Space-model）">状态空间模型（State-Space model）</h3>
<p>思想来源于信号处理，对长上下文序列进行建模，但时间复杂度大幅下降</p>
<p>在一些联想回忆任务中表现不佳</p>
<p>Mamba 很受欢迎，并成功移植到 Transformer 和 MoE 的模型中</p>
<p>线性注意力，类似于RNN，这种想法被成功扩大，MiniMax（linear attention + full attention）正在训练相当有效的模型</p>
<h3 id="kuo-san-mo-xing-diffusion-model" id="扩散模型（Diffusion-model）">扩散模型（Diffusion model）</h3>
<p>不再受自回归约束，并行生成 token ，并持续迭代改良</p>
<h2 id="liang-hua" id="量化">量化</h2>
<p>减少数字的精度（ float 转 int 或者转为更低精度的 float）</p>
<p>越少的内存意味着传输的字节数越多，延迟越低，但准确度会有所降低</p>
<p>考虑选择量化具体那一部分的权重</p>
<h2 id="mo-xing-jian-zhi" id="模型剪枝">模型剪枝</h2>
<p>拆掉昂贵模型的零件，让其变得便宜然后修好它</p>
<ol>
<li class="lvl-3">
<p>定义更快的模型架构</p>
</li>
<li class="lvl-3">
<p>使用原始模型（架构不同）初始化权重</p>
</li>
<li class="lvl-3">
<p>修复更快的模型（蒸馏）</p>
</li>
</ol>
<h2 id="tui-ce-cai-yang" id="推测采样">推测采样</h2>
<p>以上措施都是有损的，但该方法会让你鱼和熊掌兼得</p>
<p>检查比生成更快</p>
<p>使用廉价的草稿模型来生成，甚至说是猜测一些 tokens，并使用目标模型来评估这些 token，这可以并行执行</p>
<p>保证从目标模型获得精确的样本</p>
<p>可用 Medusa 和 EAGLE 更进一步优化</p>
<h1 id="shu-ju" id="数据">数据</h1>
<p>训练阶段：</p>
<p>预训练：使用原始文本（例如，来自网络的文档）进行训练</p>
<p>训练中期：使用更多高质量数据进行训练以增强能力</p>
<p>后训练：使用指令跟踪数据进行微调（或进行强化学习）以实现指令跟踪</p>
<p>在实践中，界限模糊，可能会有更多阶段。</p>
<p>……但基本思路是从[大量低质量数据]到[少量高质量数据]。</p>
<h2 id="yu-xun-lian" id="预训练">预训练</h2>
<p>基于书籍和维基百科的数据</p>
<p>来源于网络的数据非常容易受到污染，造成大预言模型的数据中毒</p>
<p>Common crawl 网络爬虫，需要对其中的内容进行处理和筛选</p>
<p>Q&amp;A 格式数据集与用户输入的内容及其响应十分相似</p>
<blockquote>
<p>不同的模型采用了不同数据集，并采用并不完全相同的处理方式</p>
</blockquote>
<p>如何合法获取数据以及处理得到高质量的数据</p>
<h2 id="guo-lu-yu-qu-zhong" id="过滤与去重">过滤与去重</h2>
<h3 id="guo-lu-suan-fa" id="过滤算法">过滤算法</h3>
<p>带有 kneser-Ney 平滑的 n-gram 模型，速度很快，但很粗糙</p>
<p>快速文本分类器，词袋嵌入</p>
<p>词袋可扩展至 g-gram，并使用哈希实现（线性分类器）</p>
<p>DSIR（重要性采样）</p>
<p><strong>通用框架</strong></p>
<p><strong>给定目标 T 和原始 R，找到与 T 相似的 R 子集，根据 R 和 T 估计某个模型并推导出评分函数，根据得分将样本保留在 R 中</strong></p>
<p>T 的生成模型 (KenLM)：score(x) = p_T(x)</p>
<p>保留 score(x) &gt;= 阈值的样本 x（随机）</p>
<p>判别分类器 (fastText)：score(x) = p(T | x)</p>
<p>保留 score(x) &gt;= 阈值的样本 x（随机）</p>
<p>重要性重采样 (DSIR)：score(x) = p_T(x) / p_R(x)</p>
<p>以与 score(x) 成比例的概率对样本 x 进行重采样</p>
<h3 id="guo-lu-ying-yong" id="过滤应用">过滤应用</h3>
<p><strong>语言识别，质量过滤，毒性过滤</strong></p>
<h2 id="qu-zhong" id="去重">去重</h2>
<p>完全重复，近似重复（相同的文本，但有几个标记不同）</p>
<p>主要使用哈希函数，存在最佳超参数用以限定桶的数量及哈希函数的数量，由插入数据的数量决定</p>
<p>Jaccard similarity</p>
<p>Jaccard (A, B) = |A 交 B| / |A 并 B|，用以判断两种集合的近似程度</p>
<p>minhash 的哈希冲突概率即为 Jaccard similarity ，可根据相似性控制适当的哈希冲突级别</p>
<p><strong>局部敏感哈希</strong>，波段 b 和每段的哈希函数数量 r 的超参数，使低于阈值的数据碰撞概率很小，高于阈值的数据碰撞概率很大，r 越大使得曲线右移并更尖锐，b越大使得曲线左移</p>
<h1 id="sft-rlhf-dui-qi" id="SFT-RLHF对齐">SFT/RLHF对齐</h1>
<p>对LM输出进行更好、更严格的控制</p>
<p>标准方法——模仿（SFT）然后强化（‘RL’ HF）</p>
<p>deepseek R1 <strong>基于结果的奖励和 GRPO 很有效果</strong></p>
<h1 id="rl-1" id="RL-2">RL</h1>
<p>CLIP 方面的知识</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://hitorikoishi.github.io">HitoriKoishi</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://hitorikoishi.github.io/2025/10/20/LLM-CS336/">https://hitorikoishi.github.io/2025/10/20/LLM-CS336/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://hitorikoishi.github.io" target="_blank">Aris系统已上线</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/LLM/">LLM</a></div><div class="post-share"><div class="social-share" data-image="/img/background_2.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related full-width" href="/2025/06/24/Go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8/" title="Go语言入门"><img class="cover" src="/img/background_1.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Go语言入门</div></div><div class="info-2"><div class="info-item-1">程序结构 声明与变量 在 Go 语言中，字面量（Literal） 的概念和 C++ 中的字面量非常相似，都是指在代码中直接表示固定值的符号或表达式。它们用于表示基本数据类型（如整数、浮点数、字符、字符串等）的常量值，而无需通过变量或计算来获取。    场景 短赋值 := 一般赋值 =     函数内声明新变量 ✅ ❌（需配合 var）   包作用域变量赋值 ❌ ✅   仅赋值（变量已声明） ❌ ✅   多变量赋值（含新变量） ✅ ❌   显式指定变量类型 ❌ ✅（配合 var）    流程控制 for Go 只有一种循环结构：for 循环。基本的 for 循环由三部分组成，它们用分号隔开，表达式外无需小括号 ( )，而大括号 &#123; &#125; 则是必须的 123for i := 0; i &lt; 10; i++ &#123;	sum += i+sum&#125; 初始化语句和后置语句是可选的，且可以去掉分号，此时for相当于C++中的while 123for sum &lt; 1000 &#123;    sum +=...</div></div></div></a></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">HitoriKoishi</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">5</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">5</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/HitoriKoishi"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/HitoriKoishi" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">record the moment</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#biao-ji-hua"><span class="toc-number">1.</span> <span class="toc-text">标记化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#zi-jie-dui-bian-ma-biao-ji-qi-bpe"><span class="toc-number">1.1.</span> <span class="toc-text">字节对编码标记器（BPE）</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#pytorch"><span class="toc-number">2.</span> <span class="toc-text">pytorch</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#zhang-liang"><span class="toc-number">2.1.</span> <span class="toc-text">张量</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#jia-gou-yu-chao-can-shu"><span class="toc-number">3.</span> <span class="toc-text">架构与超参数</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#he-xin-jia-gou"><span class="toc-number">3.1.</span> <span class="toc-text">核心架构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#biao-zhun-hua"><span class="toc-number">3.1.1.</span> <span class="toc-text">标准化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ji-huo-han-shu"><span class="toc-number">3.1.2.</span> <span class="toc-text">激活函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#jia-gou"><span class="toc-number">3.1.3.</span> <span class="toc-text">架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#wei-zhi-qian-ru"><span class="toc-number">3.1.4.</span> <span class="toc-text">位置嵌入</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#chao-can-shu"><span class="toc-number">3.2.</span> <span class="toc-text">超参数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#qian-kui-ceng-wei-du"><span class="toc-number">3.2.1.</span> <span class="toc-text">前馈层维度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#tou-bu-wei-du-yu-tou-bu-shu-liang"><span class="toc-number">3.2.2.</span> <span class="toc-text">头部维度与头部数量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#zong-heng-bi"><span class="toc-number">3.2.3.</span> <span class="toc-text">纵横比</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ci-ku-da-xiao-vocabulary-size"><span class="toc-number">3.2.4.</span> <span class="toc-text">词库大小（vocabulary size）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#jian-zhi-ji-yi-xie-qi-ta-zheng-ze-hua"><span class="toc-number">3.3.</span> <span class="toc-text">剪枝及一些其他正则化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#wen-ding-xing-ji-qiao"><span class="toc-number">3.4.</span> <span class="toc-text">稳定性技巧</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#zhu-yi-li-tou"><span class="toc-number">3.5.</span> <span class="toc-text">注意力头</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#zhuan-jia-hun-he-xi-tong-mo-e"><span class="toc-number">4.</span> <span class="toc-text">专家混合系统（MoE）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#jia-gou-1"><span class="toc-number">4.1.</span> <span class="toc-text">架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#she-ji"><span class="toc-number">4.2.</span> <span class="toc-text">设计</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#xun-lian"><span class="toc-number">4.3.</span> <span class="toc-text">训练</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#rl"><span class="toc-number">4.3.1.</span> <span class="toc-text">RL</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sui-ji-jin-si"><span class="toc-number">4.3.2.</span> <span class="toc-text">随机近似</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#qi-fa-shi-ping-heng-sun-shi"><span class="toc-number">4.3.3.</span> <span class="toc-text">启发式平衡损失</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sui-ji-xing"><span class="toc-number">4.3.4.</span> <span class="toc-text">随机性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#wen-ding-xing"><span class="toc-number">4.3.5.</span> <span class="toc-text">稳定性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#wei-diao"><span class="toc-number">4.3.6.</span> <span class="toc-text">微调</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sheng-ji-zai-zao-upcycling"><span class="toc-number">4.3.7.</span> <span class="toc-text">升级再造（upcycling）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#deep-seek-v-3-fei-mo-e"><span class="toc-number">4.4.</span> <span class="toc-text">DeepSeek V3 - 非MoE</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#zong-jie"><span class="toc-number">4.5.</span> <span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#suo-fang-ding-lu"><span class="toc-number">5.</span> <span class="toc-text">缩放定律</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#tui-li"><span class="toc-number">6.</span> <span class="toc-text">推理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#tui-li-you-hua-jian-xiao-kv-cache"><span class="toc-number">6.1.</span> <span class="toc-text">推理优化——减小 KV cache</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#gqa-group-query-attention"><span class="toc-number">6.1.1.</span> <span class="toc-text">GQA（Group-query-attention）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#mla-multi-head-latent-attention"><span class="toc-number">6.1.2.</span> <span class="toc-text">MLA（Multi-head latent attention）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cla-cross-layer-attention"><span class="toc-number">6.1.3.</span> <span class="toc-text">CLA（Cross-layer attention）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ju-bu-zhu-yi-li"><span class="toc-number">6.1.4.</span> <span class="toc-text">局部注意力</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tui-li-mo-xing-jia-gou-ti-huan"><span class="toc-number">6.2.</span> <span class="toc-text">推理模型架构替换</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#zhuang-tai-kong-jian-mo-xing-state-space-model"><span class="toc-number">6.2.1.</span> <span class="toc-text">状态空间模型（State-Space model）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kuo-san-mo-xing-diffusion-model"><span class="toc-number">6.2.2.</span> <span class="toc-text">扩散模型（Diffusion model）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#liang-hua"><span class="toc-number">6.3.</span> <span class="toc-text">量化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mo-xing-jian-zhi"><span class="toc-number">6.4.</span> <span class="toc-text">模型剪枝</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tui-ce-cai-yang"><span class="toc-number">6.5.</span> <span class="toc-text">推测采样</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#shu-ju"><span class="toc-number">7.</span> <span class="toc-text">数据</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#yu-xun-lian"><span class="toc-number">7.1.</span> <span class="toc-text">预训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#guo-lu-yu-qu-zhong"><span class="toc-number">7.2.</span> <span class="toc-text">过滤与去重</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#guo-lu-suan-fa"><span class="toc-number">7.2.1.</span> <span class="toc-text">过滤算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#guo-lu-ying-yong"><span class="toc-number">7.2.2.</span> <span class="toc-text">过滤应用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#qu-zhong"><span class="toc-number">7.3.</span> <span class="toc-text">去重</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#sft-rlhf-dui-qi"><span class="toc-number">8.</span> <span class="toc-text">SFT&#x2F;RLHF对齐</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#rl-1"><span class="toc-number">9.</span> <span class="toc-text">RL</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/10/20/LLM-CS336/" title="LLM-CS336"><img src="/img/background_2.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="LLM-CS336"/></a><div class="content"><a class="title" href="/2025/10/20/LLM-CS336/" title="LLM-CS336">LLM-CS336</a><time datetime="2025-10-20T08:18:25.000Z" title="发表于 2025-10-20 16:18:25">2025-10-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/06/24/Go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8/" title="Go语言入门"><img src="/img/background_1.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Go语言入门"/></a><div class="content"><a class="title" href="/2025/06/24/Go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8/" title="Go语言入门">Go语言入门</a><time datetime="2025-06-24T15:15:11.000Z" title="发表于 2025-06-24 23:15:11">2025-06-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/06/21/Google-File-System-%E7%AC%94%E8%AE%B0/" title="Google File System 笔记"><img src="/img/background_4.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Google File System 笔记"/></a><div class="content"><a class="title" href="/2025/06/21/Google-File-System-%E7%AC%94%E8%AE%B0/" title="Google File System 笔记">Google File System 笔记</a><time datetime="2025-06-21T12:17:57.000Z" title="发表于 2025-06-21 20:17:57">2025-06-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/02/18/c-whale-market%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/" title="c++ whale market项目总结"><img src="/img/background_3.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="c++ whale market项目总结"/></a><div class="content"><a class="title" href="/2025/02/18/c-whale-market%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/" title="c++ whale market项目总结">c++ whale market项目总结</a><time datetime="2025-02-18T10:10:30.000Z" title="发表于 2025-02-18 18:10:30">2025-02-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/16/HelloWorld/" title="HelloWorld"><img src="/img/background_2.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="HelloWorld"/></a><div class="content"><a class="title" href="/2025/01/16/HelloWorld/" title="HelloWorld">HelloWorld</a><time datetime="2025-01-16T05:38:05.000Z" title="发表于 2025-01-16 13:38:05">2025-01-16</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By HitoriKoishi</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.3</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>